#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æ‰¹é‡å›¾ç‰‡å¤„ç†æ¨¡å—ï¼ˆmedia_groupï¼‰

å¤„ç†ç¾¤ç»„/é¢‘é“ä¸­çš„æ‰¹é‡å›¾ç‰‡ä¸Šä¼ ï¼Œä½¿ç”¨ debounce æœºåˆ¶åˆå¹¶æ±‡æ€»æ¶ˆæ¯ã€‚
"""
import time
from dataclasses import dataclass, field
from typing import Any, Dict, List, Optional, Tuple

from ..config import logger
from ..utils import format_size

# å•ä¸ª media_group æœ€å¤§å›¾ç‰‡æ•°
_MAX_BATCH_ITEMS = 20
# æ®‹ç•™ batch è¿‡æœŸæ—¶é—´ï¼ˆç§’ï¼‰
_STALE_BATCH_TIMEOUT = 300
# æ–‡ä»¶ä¸‹è½½è¶…æ—¶ï¼ˆç§’ï¼‰
_DOWNLOAD_TIMEOUT = 60


@dataclass
class _MediaBatch:
    """ç¾¤ç»„/é¢‘é“æ‰¹é‡å›¾ç‰‡ä¸Šä¼ çš„ç´¯åŠ å™¨"""
    chat_id: int
    media_group_id: str
    items: List[Dict[str, Any]] = field(default_factory=list)
    status_message_id: Optional[int] = None
    first_message_id: Optional[int] = None
    message_thread_id: Optional[int] = None
    delete_delay: int = 0
    flush_task: Optional[Any] = None
    updated_at: float = field(default_factory=time.monotonic)


_media_group_batches: Dict[Tuple[int, str], _MediaBatch] = {}


def _cleanup_stale_batches() -> None:
    """æ¸…ç†è¶…è¿‡ _STALE_BATCH_TIMEOUT ç§’çš„æ®‹ç•™ batchï¼Œé˜²æ­¢å†…å­˜æ³„æ¼"""
    now = time.monotonic()
    stale_keys = [
        k for k, v in _media_group_batches.items()
        if now - v.updated_at > _STALE_BATCH_TIMEOUT
    ]
    for k in stale_keys:
        batch = _media_group_batches.pop(k, None)
        if batch and batch.flush_task:
            batch.flush_task.cancel()
        logger.warning(f"æ¸…ç†æ®‹ç•™ batch: chat={k[0]} group={k[1]}, items={len(batch.items) if batch else '?'}")


def _format_batch_summary(
    urls: List[str],
    success_count: int,
    total_count: int,
    total_size_bytes: int,
    failure_count: int,
) -> str:
    """æ ¼å¼åŒ–æ‰¹é‡ä¸Šä¼ æ±‡æ€»æ¶ˆæ¯ï¼ˆè‡ªåŠ¨æˆªæ–­ä»¥é¿å…è¶…è¿‡4096å­—ç¬¦ï¼‰"""
    lines = [f"âœ… *æ‰¹é‡ä¸Šä¼ å®Œæˆ* (æˆåŠŸ: {success_count} / æ€»æ•°: {total_count})"]

    if urls:
        lines.append("")
        # è¶…è¿‡10å¼ æ—¶ä½¿ç”¨ç´§å‡‘æ¨¡å¼
        if len(urls) <= 10:
            for i, url in enumerate(urls, 1):
                lines.append(f"{i}. `{url}`")
        else:
            # ç´§å‡‘æ¨¡å¼ï¼šåªæ˜¾ç¤ºå‰8æ¡ + çœç•¥æç¤º
            for i, url in enumerate(urls[:8], 1):
                lines.append(f"{i}. `{url}`")
            lines.append(f"... åŠå…¶ä»– {len(urls) - 8} å¼ ")

    lines.append("")
    lines.append(f"ğŸ“¦ *æ€»å¤§å°:* {format_size(total_size_bytes)}")
    if failure_count:
        lines.append(f"âŒ *å¤±è´¥:* {failure_count} å¼ ")
    lines.append("ğŸ’¡ é“¾æ¥æ°¸ä¹…æœ‰æ•ˆ")
    return "\n".join(lines)


async def _flush_media_group(
    batch_key: Tuple[int, str],
    bot: Any,
    debounce_seconds: float = 1.5,
) -> None:
    """å»¶è¿Ÿå¤„ç†æ‰¹é‡å›¾ç‰‡å¹¶å‘é€æ±‡æ€»æ¶ˆæ¯"""
    import asyncio
    from ..services.file_service import record_existing_telegram_file
    from ..utils import get_domain
    from .state import _inc_bot_stats

    try:
        await asyncio.sleep(debounce_seconds)
    except asyncio.CancelledError:
        return

    # å…¥å£å¤„æ¸…ç†æ®‹ç•™ batch
    _cleanup_stale_batches()

    batch = _media_group_batches.get(batch_key)
    if not batch:
        return

    # ç¡®ä¿æ˜¯å½“å‰ä»»åŠ¡åœ¨æ‰§è¡Œ
    current_task = asyncio.current_task()
    if batch.flush_task is not None and batch.flush_task is not current_task:
        return

    # ç«æ€æ ¡éªŒï¼šå¦‚æœåœ¨ sleep æœŸé—´æœ‰æ–°å›¾ç‰‡åˆ°è¾¾ï¼Œé‡æ–°è°ƒåº¦å‰©ä½™ç­‰å¾…æ—¶é—´
    elapsed = time.monotonic() - batch.updated_at
    if elapsed < debounce_seconds:
        remaining = debounce_seconds - elapsed
        batch.flush_task = asyncio.create_task(
            _flush_media_group(batch_key, bot, debounce_seconds=remaining)
        )
        return

    _media_group_batches.pop(batch_key, None)

    base_url = get_domain(None)
    urls: List[str] = []
    total_size_bytes = 0
    total_count = len(batch.items)
    failure_count = 0

    # æŒ‰æ¶ˆæ¯IDæ’åºå¤„ç†
    for item in sorted(batch.items, key=lambda x: x.get("message_id", 0)):
        try:
            file_id = item.get("file_id")
            if not file_id:
                failure_count += 1
                continue

            file_info = await asyncio.wait_for(bot.get_file(file_id), timeout=_DOWNLOAD_TIMEOUT)
            file_bytes = await asyncio.wait_for(file_info.download_as_bytearray(), timeout=_DOWNLOAD_TIMEOUT)

            result = record_existing_telegram_file(
                file_id=file_id,
                file_unique_id=item.get("file_unique_id"),
                file_path=getattr(file_info, "file_path", "") or "",
                file_content=bytes(file_bytes),
                filename=item.get("filename", ""),
                content_type=item.get("content_type", "image/jpeg"),
                username=item.get("username", ""),
                source="telegram_group",
                auth_token=item.get("auth_token"),
                is_group_upload=True,
                group_message_id=item.get("message_id"),
                group_chat_id=batch.chat_id,
            )

            if not result:
                failure_count += 1
                continue

            urls.append(f"{base_url}/image/{result['encrypted_id']}")
            total_size_bytes += int(result.get("file_size", 0) or 0)
        except Exception as e:
            failure_count += 1
            logger.error(f"æ‰¹é‡å¤„ç†å›¾ç‰‡å¤±è´¥: {e}")

    success_count = len(urls)
    failure_count = total_count - success_count

    # æ›´æ–°è¿è¡Œæ—¶ç»Ÿè®¡
    _inc_bot_stats(success=success_count, failed=failure_count)

    summary_text = _format_batch_summary(
        urls, success_count, total_count, total_size_bytes, failure_count
    )
    # PLACEHOLDER_FLUSH_SEND

    reply_msg_id: Optional[int] = None

    # ä¼˜å…ˆç¼–è¾‘å·²æœ‰çš„çŠ¶æ€æ¶ˆæ¯
    if batch.status_message_id:
        try:
            await bot.edit_message_text(
                chat_id=batch.chat_id,
                message_id=batch.status_message_id,
                text=summary_text,
                parse_mode="Markdown",
            )
            reply_msg_id = batch.status_message_id
        except Exception:
            pass

    # å¦‚æœç¼–è¾‘å¤±è´¥ï¼Œå‘é€æ–°æ¶ˆæ¯
    if reply_msg_id is None:
        send_kwargs: Dict[str, Any] = {
            "chat_id": batch.chat_id,
            "text": summary_text,
            "parse_mode": "Markdown",
        }
        if batch.message_thread_id is not None:
            send_kwargs["message_thread_id"] = batch.message_thread_id
        if batch.first_message_id is not None:
            send_kwargs["reply_to_message_id"] = batch.first_message_id

        try:
            sent = await bot.send_message(**send_kwargs)
            reply_msg_id = getattr(sent, "message_id", None)
        except Exception:
            send_kwargs.pop("reply_to_message_id", None)
            try:
                sent = await bot.send_message(**send_kwargs)
                reply_msg_id = getattr(sent, "message_id", None)
            except Exception as e:
                logger.error(f"å‘é€æ‰¹é‡æ±‡æ€»æ¶ˆæ¯å¤±è´¥: {e}")

    # å»¶è¿Ÿåˆ é™¤å›å¤
    if batch.delete_delay > 0 and reply_msg_id:
        async def delayed_delete():
            try:
                await asyncio.sleep(batch.delete_delay)
                await bot.delete_message(chat_id=batch.chat_id, message_id=reply_msg_id)
            except Exception as e:
                logger.debug(f"åˆ é™¤å›å¤æ¶ˆæ¯å¤±è´¥: {e}")
        asyncio.create_task(delayed_delete())
